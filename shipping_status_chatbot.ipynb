{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2862e1d603f74c398dfea05eed500b64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47fa26400e0944efb6565098a2e51813",
              "IPY_MODEL_ffb4343b934d48e6bb1c1d36e27bd200",
              "IPY_MODEL_89dfed9ba6ba4470af14c808ead02628"
            ],
            "layout": "IPY_MODEL_ed2c91cfcbb3481cb2ac143efe32e1d2"
          }
        },
        "47fa26400e0944efb6565098a2e51813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57491c533e3241be9365c613e5e4d3ed",
            "placeholder": "​",
            "style": "IPY_MODEL_d044175bf8ef44f38bf0248a6ada100d",
            "value": "100%"
          }
        },
        "ffb4343b934d48e6bb1c1d36e27bd200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b774e4cb2f3e4bb3b622861ad2778864",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6dabdd478744a0d9d23d91f8045adc4",
            "value": 1
          }
        },
        "89dfed9ba6ba4470af14c808ead02628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ab772181cfc47d8afe105f9a41298a7",
            "placeholder": "​",
            "style": "IPY_MODEL_616748a9311e4f11bb4df04f14981673",
            "value": " 1/1 [00:04&lt;00:00,  4.22s/it]"
          }
        },
        "ed2c91cfcbb3481cb2ac143efe32e1d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57491c533e3241be9365c613e5e4d3ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d044175bf8ef44f38bf0248a6ada100d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b774e4cb2f3e4bb3b622861ad2778864": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6dabdd478744a0d9d23d91f8045adc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ab772181cfc47d8afe105f9a41298a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "616748a9311e4f11bb4df04f14981673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install libraries of langchain, openai, pinecone-client."
      ],
      "metadata": {
        "id": "pLJl6ypeJvIY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-o8rtU3IKMq",
        "outputId": "36f6e718-bcb5-41db-cd5a-4a58ba9c918d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.8/811.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.0/211.0 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-text-splitters 0.3.0 requires langchain-core<0.4.0,>=0.3.0, but you have langchain-core 0.1.23 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU \\\n",
        "    langchain==0.1.6 langchain-community==0.0.19 langchain-core==0.1.23 \\\n",
        "    openai==1.6.1 \\\n",
        "    pinecone-client==3.1.0 \\\n",
        "    tiktoken==0.5.2\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from tqdm.auto import tqdm\n",
        "from langchain.vectorstores import Pinecone"
      ],
      "metadata": {
        "id": "yV9TYT1PMkCa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"YOUR_OPENAI_API_KEY\") #you need to use your own ChatGPT API Key\n",
        "\n",
        "chat = ChatOpenAI(\n",
        "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
        "    model='gpt-3.5-turbo'\n",
        ")"
      ],
      "metadata": {
        "id": "p0mXk0VfMnkV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65d68540-73f9-4955-e8c7-933ebac6751a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# simple test\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
        "    HumanMessage(content=\"Hi AI, how are you today?\"),\n",
        "    AIMessage(content=\"I'm great thank you. How can I help you?\"),\n",
        "    HumanMessage(content=\"I'd like to understand string theory.\")\n",
        "]\n",
        "res = chat(messages)\n",
        "print(res.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sNNkmlZHQdWA",
        "outputId": "e089d08a-5a89-4bf6-c7d6-158ca49879c0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "String theory is a theoretical framework in physics that attempts to reconcile quantum mechanics and general relativity. It proposes that the fundamental building blocks of the universe are not particles but tiny, vibrating strings. These strings can have different modes of vibration, and the way they vibrate determines their properties, such as mass and charge.\n",
            "\n",
            "String theory suggests that there are multiple dimensions beyond the four we experience in our everyday lives. It also predicts the existence of additional particles beyond those observed in the Standard Model of particle physics.\n",
            "\n",
            "One of the key ideas in string theory is the concept of supersymmetry, which posits a relationship between particles with different spin values. Supersymmetry could potentially resolve some of the outstanding problems in particle physics, such as the hierarchy problem and the nature of dark matter.\n",
            "\n",
            "However, string theory is still a work in progress and has not yet been experimentally confirmed. Researchers continue to explore its implications and try to develop ways to test its predictions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create database of shipping status"
      ],
      "metadata": {
        "id": "CKQPhwrEXIdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "shipping_data = [\n",
        "    {\n",
        "        \"order_id\": str(i),\n",
        "        \"customer_name\": name,\n",
        "        \"status\": status,\n",
        "        \"order_date\": order_date,\n",
        "        \"shipping_date\": shipping_date,\n",
        "        \"delivery_date\": delivery_date,\n",
        "        \"shipping_address\": address,\n",
        "        \"carrier\": carrier,\n",
        "        \"tracking_number\": tracking_number,\n",
        "        \"item_description\": item,\n",
        "        \"quantity\": quantity,\n",
        "        \"shipping_cost\": cost,\n",
        "        \"shipper_name\": shipper_name,\n",
        "        \"shipper_phone_number\": shipper_phone,\n",
        "        \"current_location\": address if status == \"Shipped\" else current_location\n",
        "    }\n",
        "    for i, (name, status, order_date, shipping_date, delivery_date, address, carrier, tracking_number, item, quantity, cost, shipper_name, shipper_phone, current_location) in enumerate([\n",
        "        (\"Alice Johnson\", \"Shipped\", \"2023-10-25\", \"2023-10-27\", \"2023-11-05\", \"123 Maple St, Chicago\", \"FedEx\", \"1Z9999\", \"Laptop\", 1, 15.99, \"John Doe\", \"+1-800-463-3339\", \"123 Maple St, Chicago\"),\n",
        "        (\"Bob Smith\", \"Processing\", \"2023-10-28\", \"2023-10-29\", \"2023-11-07\", \"456 Oak St, New York\", \"UPS\", \"1Z9988\", \"Smartphone\", 1, 10.50, \"Sarah Lee\", \"+1-800-742-5877\", \"New York\"),\n",
        "        (\"Charlie Brown\", \"Delivered\", \"2023-10-20\", \"2023-10-22\", \"2023-10-31\", \"789 Pine St, Los Angeles\", \"USPS\", \"9400\", \"Tablet\", 1, 12.00, \"Delivered\", \"+1-800-275-8777\", \"Los Angeles\"),\n",
        "        (\"David Lee\", \"Shipped\", \"2023-10-26\", \"2023-10-29\", \"2023-11-06\", \"321 Cedar St, Houston\", \"DHL\", \"JD0001\", \"Headphones\", 2, 8.75, \"Michael Brown\", \"+1-800-225-5345\", \"321 Cedar St, Houston\"),\n",
        "        (\"Eve Thompson\", \"Cancelled\", \"2023-10-29\", \"2023-10-30\", \"2023-10-30\", \"654 Elm St, Miami\", \"UPS\", \"1Z9977\", \"Smartwatch\", 1, 0.00, \"Cancelled\", \"+1-800-742-5877\", \"Miami\"),\n",
        "        (\"Frank White\", \"Processing\", \"2023-10-30\", \"2023-10-31\", \"2023-11-08\", \"987 Birch St, Phoenix\", \"UPS\", \"1Z9966\", \"Camera\", 1, 9.25, \"Emily Smith\", \"+1-800-742-5877\", \"Phoenix\"),\n",
        "        (\"Grace Miller\", \"Delivered\", \"2023-10-19\", \"2023-10-21\", \"2023-10-30\", \"111 Spruce St, San Francisco\", \"FedEx\", \"1Z8888\", \"Bluetooth Speaker\", 1, 7.80, \"Delivered\", \"+1-800-463-3339\", \"San Francisco\"),\n",
        "        (\"Hannah Adams\", \"Shipped\", \"2023-10-27\", \"2023-10-30\", \"2023-11-09\", \"222 Walnut St, Seattle\", \"DHL\", \"JD0002\", \"E-reader\", 1, 6.90, \"Carlos Green\", \"+1-800-225-5345\", \"222 Walnut St, Seattle\"),\n",
        "        (\"Isaac Clark\", \"Pending\", \"2023-10-31\", \"2023-11-01\", \"2023-11-10\", \"333 Chestnut St, Denver\", \"USPS\", \"9401\", \"Wireless Mouse\", 3, 5.50, \"Pending\", \"+1-800-275-8777\", \"Denver\"),\n",
        "    ])\n",
        "]\n",
        "\n",
        "# Convert to DataFrame for easy data manipulation\n",
        "shipping_df = pd.DataFrame(shipping_data)\n",
        "\n",
        "#shipping_df.to_csv(\"shipping_status.csv\", index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "3SJQJfZnVkFL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We begin by initializing our connection to Pinecone, this requires a [free API key](https://app.pinecone.io)."
      ],
      "metadata": {
        "id": "aKQqphG_rRFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "pc = Pinecone(api_key=\"YOUR_API_KEY\") #use your own Pinecone API Key\n",
        "spec = ServerlessSpec(\n",
        "    cloud=\"aws\", region=\"us-east-1\"\n",
        ")"
      ],
      "metadata": {
        "id": "TjOurccNphxc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we initialize the index. We will be using OpenAI's `text-embedding-ada-002` model for creating the embeddings, so we set the `dimension` to `1536`."
      ],
      "metadata": {
        "id": "SyJgtsUvt9tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = 'llama-2-rag'\n",
        "existing_indexes = [\n",
        "    index_info[\"name\"] for index_info in pc.list_indexes()\n",
        "]\n",
        "\n",
        "# check if index already exists (it shouldn't if this is first time)\n",
        "if index_name not in existing_indexes:\n",
        "    # if does not exist, create index\n",
        "    pc.create_index(\n",
        "        index_name,\n",
        "        dimension=1536,  # dimensionality of ada 002\n",
        "        metric='dotproduct',\n",
        "        spec=spec\n",
        "    )\n",
        "    # wait for index to be initialized\n",
        "    while not pc.describe_index(index_name).status['ready']:\n",
        "        time.sleep(1)\n",
        "\n",
        "# connect to index\n",
        "index = pc.Index(index_name)\n",
        "time.sleep(1)\n",
        "# view index stats\n",
        "index.describe_index_stats()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qX3w_VbgqOfu",
        "outputId": "84945da2-101e-4381-a94a-d4ad15b205ff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {'': {'vector_count': 9}},\n",
              " 'total_vector_count': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "embed and index all our dataset"
      ],
      "metadata": {
        "id": "5qX2JhJjfDbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "for i in tqdm(range(0, len(shipping_df), batch_size)):\n",
        "    i_end = min(len(shipping_df), i + batch_size)\n",
        "    batch = shipping_df.iloc[i:i_end]\n",
        "\n",
        "    # Generate unique IDs for each record\n",
        "    ids = [f\"order-{x['order_id']}\" for _, x in batch.iterrows()]\n",
        "\n",
        "    # Extract detailed text to embed, including all key order information\n",
        "    texts = [\n",
        "        f\"Order ID: {x['order_id']}, Customer: {x['customer_name']}, Status: {x['status']}, Shipper Name: {x['shipper_name']}, Shipper Phone Number: {x['shipper_phone_number']}, \"\n",
        "        f\"Order Date: {x['order_date']}, Shipping Date: {x['shipping_date']}, Delivery Date: {x['delivery_date']}, \"\n",
        "        f\"Shipping Address: {x['shipping_address']}, Carrier: {x['carrier']}, Tracking Number: {x['tracking_number']}, \"\n",
        "        f\"Item: {x['item_description']}, Quantity: {x['quantity']}, Shipping Cost: ${x['shipping_cost']}, Current Location: {x['current_location']}\"\n",
        "        for _, x in batch.iterrows()\n",
        "    ]\n",
        "\n",
        "    # Generate embeddings for each record\n",
        "    embeds = embed_model.embed_documents(texts)\n",
        "\n",
        "    # Prepare metadata, ensuring each field is included\n",
        "    metadata = [\n",
        "        {\n",
        "            'order_id': x['order_id'],\n",
        "            'customer_name': x['customer_name'],\n",
        "            'status': x['status'],\n",
        "            'order_date': x['order_date'],\n",
        "            'shipping_date': x['shipping_date'],\n",
        "            'delivery_date': x['delivery_date'],\n",
        "            'shipping_address': x['shipping_address'],\n",
        "            'carrier': x['carrier'],\n",
        "            'tracking_number': x['tracking_number'],\n",
        "            'item_description': x['item_description'],\n",
        "            'quantity': x['quantity'],\n",
        "            'shipping_cost': x['shipping_cost'],\n",
        "            'shipper_name': x['shipper_name'],\n",
        "            'shipper_phone_number': x['shipper_phone_number'],\n",
        "            'current_location': x['current_location'],\n",
        "            'text': texts[j]  # Add the text used for embedding to metadata for reference\n",
        "        }\n",
        "        for j, x in batch.iterrows()\n",
        "    ]\n",
        "\n",
        "    # Upsert to Pinecone, with metadata containing detailed fields\n",
        "    index.upsert(vectors=zip(ids, embeds, metadata))\n",
        "\n"
      ],
      "metadata": {
        "id": "XSptac5GuHdX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "2862e1d603f74c398dfea05eed500b64",
            "47fa26400e0944efb6565098a2e51813",
            "ffb4343b934d48e6bb1c1d36e27bd200",
            "89dfed9ba6ba4470af14c808ead02628",
            "ed2c91cfcbb3481cb2ac143efe32e1d2",
            "57491c533e3241be9365c613e5e4d3ed",
            "d044175bf8ef44f38bf0248a6ada100d",
            "b774e4cb2f3e4bb3b622861ad2778864",
            "b6dabdd478744a0d9d23d91f8045adc4",
            "6ab772181cfc47d8afe105f9a41298a7",
            "616748a9311e4f11bb4df04f14981673"
          ]
        },
        "outputId": "a8d1b4a7-14a2-4127-97fc-db0e3da52f6c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2862e1d603f74c398dfea05eed500b64"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index.describe_index_stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "RXVY-ob_gePE",
        "outputId": "d58b227e-76aa-4ec4-b32a-fdab3bb96332"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Index.describe_index_stats of <pinecone.data.index.Index object at 0x7fa0a93f86a0>>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pinecone.data.index.Index.describe_index_stats</b><br/>def describe_index_stats(filter: Optional[Dict[str, Union[str, float, int, bool, List, dict]]]=None, **kwargs) -&gt; DescribeIndexStatsResponse</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pinecone/data/index.py</a>The DescribeIndexStats operation returns statistics about the index&#x27;s contents.\n",
              "For example: The vector count per namespace and the number of dimensions.\n",
              "\n",
              "API reference: https://docs.pinecone.io/reference/describe_index_stats_post\n",
              "\n",
              "Examples:\n",
              "    &gt;&gt;&gt; index.describe_index_stats()\n",
              "    &gt;&gt;&gt; index.describe_index_stats(filter={&#x27;key&#x27;: &#x27;value&#x27;})\n",
              "\n",
              "Args:\n",
              "    filter (Dict[str, Union[str, float, int, bool, List, dict]]):\n",
              "    If this parameter is present, the operation only returns statistics for vectors that satisfy the filter.\n",
              "    See https://www.pinecone.io/docs/metadata-filtering/.. [optional]\n",
              "\n",
              "Returns: DescribeIndexStatsResponse object which contains stats about the index.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 473);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Pinecone\n",
        "\n",
        "\n",
        "# initialize the vector store object\n",
        "vectorstore = Pinecone(\n",
        "    index, embed_model.embed_query, text_key='text'\n",
        ")\n",
        "def augment_prompt(query: str):\n",
        "  results = vectorstore.similarity_search(query, k=1)\n",
        "  source_knowledge = \"\\n\".join([x.page_content for x in results])\n",
        "  augmented_prompt = f\"\"\"\n",
        "  You are an AI assistant, you role is to support customer about their order status, provide exact and concise information about their order.\n",
        "  We provided database about features of order status such as customer name, order day, shipper day, quantity, carrier.\n",
        "  Ask customer about their order id and what information they want to know.\n",
        "  You need to answer only the information about related to order statuses in database, if customer query unrelevant information, ask them to input another query.\n",
        "  Be sure that you don't answer unrelevanted information.\n",
        "  The following is the shipping status database:\n",
        "  {shipping_df}\n",
        "  If customer think that there's any somthing wrong or problem with their order, ask them to contact customer service at hamy95637@gmail.com\n",
        "  Contexts:\n",
        "  {source_knowledge}\n",
        "\n",
        "  * customer_name: the name of the person receive the order\n",
        "  * status: the current order status, is the order being shipped, delivered, pending or cancellled?\n",
        "  * order_date: the date that the order is ordered\n",
        "  * delivery_date: the date that the order is or will be expected to be shipped or done.\n",
        "  * shipping_date: the date that the seller transfer the order to shipper, and the order move.\n",
        "  * shipping_adress: the order is shipped to this adress\n",
        "  * carrier: shipping unit which is responsible for delivery\n",
        "  * tracking_number: the unique number that the admin use for tracking more details of the order if there is any problem.\n",
        "  * item_description: one of the information on the contents of the package. It is the name of item the customer ordered.\n",
        "  * quantity: one of the information on the contents of the package. It express the number of item in the package ordered.\n",
        "  * shipping_cost: the cost of the order the customer must pay.\n",
        "  * shipper_name: the name of the person deliver your order\n",
        "  * shipper_phone_number: the phone number of your shipper, you can contact with the shipper by this.\n",
        "  * current_location: the location of the order in realtime, if the order was shipped, this location will be the shipping address.\n",
        "  Query: {query}\"\"\"\n",
        "  return augmented_prompt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sJxsqH4gmTV",
        "outputId": "9352a4a6-ffe6-4898-e51c-c103e011f3ba"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/pinecone.py:68: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    SystemMessage(content=\"You are an assistant that provides short and concise shipping status updates based on order information.\"),\n",
        "    HumanMessage(content=\"Hi AI, can you tell me about my shipping status?\"),\n",
        "    AIMessage(content=\"Sure, can you tell me your order id?\"),\n",
        "    HumanMessage(content=\"My order id is 0.\"),\n",
        "    AIMessage(content=\"what do you want to know about your order\"),\n",
        "    HumanMessage(content=\"I want to know about shipping cost\"),\n",
        "    AIMessage(content=\"Your shipping cost of order id 0 is 15.99\"),\n",
        "    HumanMessage(content=\"ok, i want to know about another order\"),\n",
        "    AIMessage(content=\"Sure, can you tell me your order id?\")\n",
        "]\n",
        "while True:\n",
        "    # Get the user question\n",
        "    query = input()\n",
        "\n",
        "    # Check if the user wants to exit\n",
        "    if query.lower() == 'exit':\n",
        "        print(\"Exiting the program. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Generate prompt based on the question\n",
        "    prompt = HumanMessage(content=augment_prompt(query))\n",
        "\n",
        "    # Add to messages\n",
        "    messages.append(prompt)\n",
        "\n",
        "    # Send to OpenAI model and get response\n",
        "    res = chat(messages)\n",
        "    print(\"Response:\", res.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ngpw8fpbnbvD",
        "outputId": "1ae5d45a-15a4-4539-e512-c2798b5fbf58"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "Response: I'm sorry, I didn't understand your query. Please provide your order id and the information you would like to know about your order.\n",
            "my order id and i want to know when my order will be come\n",
            "Response: Please provide me with your order ID so I can check the expected delivery date for your order.\n",
            "my order id is 1\n",
            "Response: Your order with id 1 is currently in the processing status. It was ordered on 2023-10-28, shipped on 2023-10-29, and is expected to be delivered by 2023-11-07. The carrier is UPS and the item is a Smartphone. If you need further assistance, feel free to ask.\n",
            "how much\n",
            "Response: I'm sorry, but could you please provide a specific question related to your order status?\n",
            "how much money \n",
            "Response: Please clarify your query so I can provide you with the relevant information regarding your order.\n",
            "how much money the packgae cost\n",
            "Response: The package for order ID 7 costs $6.90.\n",
            "but my order is 1\n",
            "Response: The shipping cost for your order 1 is $10.50.\n",
            "are you sure\n",
            "Response: I'm here to provide you with information about your order. If you have any specific questions, feel free to ask!\n",
            "exit\n",
            "Exiting the program. Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z8ClZDEfrrdx"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}